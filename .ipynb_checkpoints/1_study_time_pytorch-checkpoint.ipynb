{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:19:01.767266Z",
     "start_time": "2019-10-03T11:19:00.902611Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:19:01.774246Z",
     "start_time": "2019-10-03T11:19:01.770256Z"
    }
   },
   "outputs": [],
   "source": [
    "study_time_lst = [5, 2, 12, 8, 15, 10, 11, 17, 7.5, 3]\n",
    "score_lst = [60, 40, 96, 72, 100, 98, 89, 96, 80, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:19:01.786215Z",
     "start_time": "2019-10-03T11:19:01.776240Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.array(study_time_lst, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:19:01.797184Z",
     "start_time": "2019-10-03T11:19:01.788208Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = np.array(score_lst, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:19:01.809176Z",
     "start_time": "2019-10-03T11:19:01.799193Z"
    }
   },
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:19:04.743343Z",
     "start_time": "2019-10-03T11:19:01.811175Z"
    }
   },
   "outputs": [],
   "source": [
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.001 \n",
    "epochs = 200\n",
    "\n",
    "model = linearRegression(inputDim, outputDim)\n",
    "##### For GPU #######\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:19:04.752276Z",
     "start_time": "2019-10-03T11:19:04.746306Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:19:06.894545Z",
     "start_time": "2019-10-03T11:19:04.756269Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6142.6475, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 0, loss 6142.6474609375\n",
      "tensor(3972.9526, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 1, loss 3972.95263671875\n",
      "tensor(2615.4546, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 2, loss 2615.45458984375\n",
      "tensor(1766.0901, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 3, loss 1766.090087890625\n",
      "tensor(1234.6292, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 4, loss 1234.629150390625\n",
      "tensor(902.0586, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 5, loss 902.05859375\n",
      "tensor(693.9196, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 6, loss 693.9195556640625\n",
      "tensor(563.6285, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 7, loss 563.6285400390625\n",
      "tensor(482.0418, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 8, loss 482.0418395996094\n",
      "tensor(430.9260, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 9, loss 430.92596435546875\n",
      "tensor(398.8737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 10, loss 398.8736877441406\n",
      "tensor(378.7481, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 11, loss 378.74810791015625\n",
      "tensor(366.0843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 12, loss 366.0843200683594\n",
      "tensor(358.0890, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 13, loss 358.0890197753906\n",
      "tensor(353.0144, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 14, loss 353.0143737792969\n",
      "tensor(349.7672, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 15, loss 349.76715087890625\n",
      "tensor(347.6633, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 16, loss 347.66326904296875\n",
      "tensor(346.2746, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 17, loss 346.27459716796875\n",
      "tensor(345.3336, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 18, loss 345.3336486816406\n",
      "tensor(344.6728, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 19, loss 344.6727600097656\n",
      "tensor(344.1871, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 20, loss 344.1871032714844\n",
      "tensor(343.8113, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 21, loss 343.811279296875\n",
      "tensor(343.5041, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 22, loss 343.5041198730469\n",
      "tensor(343.2400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 23, loss 343.2400207519531\n",
      "tensor(343.0029, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 24, loss 343.0029296875\n",
      "tensor(342.7828, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 25, loss 342.7828063964844\n",
      "tensor(342.5732, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 26, loss 342.5732421875\n",
      "tensor(342.3705, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 27, loss 342.3704528808594\n",
      "tensor(342.1720, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 28, loss 342.1720275878906\n",
      "tensor(341.9762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 29, loss 341.9761962890625\n",
      "tensor(341.7822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 30, loss 341.78216552734375\n",
      "tensor(341.5894, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 31, loss 341.5894470214844\n",
      "tensor(341.3973, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 32, loss 341.3973388671875\n",
      "tensor(341.2059, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 33, loss 341.2059020996094\n",
      "tensor(341.0148, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 34, loss 341.0148010253906\n",
      "tensor(340.8240, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 35, loss 340.82403564453125\n",
      "tensor(340.6335, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 36, loss 340.633544921875\n",
      "tensor(340.4432, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 37, loss 340.4432067871094\n",
      "tensor(340.2532, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 38, loss 340.253173828125\n",
      "tensor(340.0632, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 39, loss 340.063232421875\n",
      "tensor(339.8735, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 40, loss 339.8735046386719\n",
      "tensor(339.6839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 41, loss 339.68389892578125\n",
      "tensor(339.4944, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 42, loss 339.49444580078125\n",
      "tensor(339.3052, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 43, loss 339.30523681640625\n",
      "tensor(339.1161, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 44, loss 339.11614990234375\n",
      "tensor(338.9272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 45, loss 338.92718505859375\n",
      "tensor(338.7384, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 46, loss 338.7384338378906\n",
      "tensor(338.5498, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 47, loss 338.5498046875\n",
      "tensor(338.3614, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 48, loss 338.36138916015625\n",
      "tensor(338.1730, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 49, loss 338.17303466796875\n",
      "tensor(337.9850, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 50, loss 337.9849853515625\n",
      "tensor(337.7969, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 51, loss 337.79693603515625\n",
      "tensor(337.6091, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 52, loss 337.6091003417969\n",
      "tensor(337.4214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 53, loss 337.42144775390625\n",
      "tensor(337.2339, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 54, loss 337.23388671875\n",
      "tensor(337.0465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 55, loss 337.0465393066406\n",
      "tensor(336.8594, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 56, loss 336.859375\n",
      "tensor(336.6724, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 57, loss 336.6723937988281\n",
      "tensor(336.4854, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 58, loss 336.48541259765625\n",
      "tensor(336.2988, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 59, loss 336.29876708984375\n",
      "tensor(336.1122, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 60, loss 336.1121826171875\n",
      "tensor(335.9257, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 61, loss 335.92572021484375\n",
      "tensor(335.7395, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 62, loss 335.739501953125\n",
      "tensor(335.5534, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 63, loss 335.5533752441406\n",
      "tensor(335.3675, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 64, loss 335.36749267578125\n",
      "tensor(335.1816, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 65, loss 335.18157958984375\n",
      "tensor(334.9960, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 66, loss 334.9960021972656\n",
      "tensor(334.8105, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 67, loss 334.81048583984375\n",
      "tensor(334.6252, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 68, loss 334.6251525878906\n",
      "tensor(334.4400, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 69, loss 334.44000244140625\n",
      "tensor(334.2550, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 70, loss 334.2550354003906\n",
      "tensor(334.0701, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 71, loss 334.0700988769531\n",
      "tensor(333.8853, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 72, loss 333.8853454589844\n",
      "tensor(333.7009, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 73, loss 333.70086669921875\n",
      "tensor(333.5164, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 74, loss 333.5164489746094\n",
      "tensor(333.3323, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 75, loss 333.332275390625\n",
      "tensor(333.1480, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 76, loss 333.1480407714844\n",
      "tensor(332.9642, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 77, loss 332.96417236328125\n",
      "tensor(332.7803, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 78, loss 332.78033447265625\n",
      "tensor(332.5967, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 79, loss 332.5967102050781\n",
      "tensor(332.4132, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 80, loss 332.4131774902344\n",
      "tensor(332.2298, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 81, loss 332.22979736328125\n",
      "tensor(332.0467, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 82, loss 332.04669189453125\n",
      "tensor(331.8637, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 83, loss 331.8636779785156\n",
      "tensor(331.6808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 84, loss 331.68084716796875\n",
      "tensor(331.4981, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 85, loss 331.4981384277344\n",
      "tensor(331.3156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 86, loss 331.3155517578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(331.1331, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 87, loss 331.1330871582031\n",
      "tensor(330.9509, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 88, loss 330.95086669921875\n",
      "tensor(330.7687, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 89, loss 330.76873779296875\n",
      "tensor(330.5868, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 90, loss 330.5867919921875\n",
      "tensor(330.4050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 91, loss 330.40496826171875\n",
      "tensor(330.2233, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 92, loss 330.22332763671875\n",
      "tensor(330.0418, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 93, loss 330.0418395996094\n",
      "tensor(329.8605, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 94, loss 329.86053466796875\n",
      "tensor(329.6793, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 95, loss 329.6792907714844\n",
      "tensor(329.4983, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 96, loss 329.4983215332031\n",
      "tensor(329.3174, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 97, loss 329.3173828125\n",
      "tensor(329.1367, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 98, loss 329.13665771484375\n",
      "tensor(328.9560, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 99, loss 328.95599365234375\n",
      "tensor(328.7755, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 100, loss 328.7755432128906\n",
      "tensor(328.5953, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 101, loss 328.59527587890625\n",
      "tensor(328.4152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 102, loss 328.4151916503906\n",
      "tensor(328.2352, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 103, loss 328.23516845703125\n",
      "tensor(328.0554, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 104, loss 328.05535888671875\n",
      "tensor(327.8755, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 105, loss 327.87554931640625\n",
      "tensor(327.6961, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 106, loss 327.6960754394531\n",
      "tensor(327.5167, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 107, loss 327.5166931152344\n",
      "tensor(327.3375, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 108, loss 327.3374938964844\n",
      "tensor(327.1584, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 109, loss 327.1583557128906\n",
      "tensor(326.9794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 110, loss 326.9794006347656\n",
      "tensor(326.8006, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 111, loss 326.80059814453125\n",
      "tensor(326.6219, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 112, loss 326.6219177246094\n",
      "tensor(326.4434, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 113, loss 326.44342041015625\n",
      "tensor(326.2652, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 114, loss 326.26519775390625\n",
      "tensor(326.0869, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 115, loss 326.08685302734375\n",
      "tensor(325.9089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 116, loss 325.90887451171875\n",
      "tensor(325.7310, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 117, loss 325.73101806640625\n",
      "tensor(325.5532, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 118, loss 325.55322265625\n",
      "tensor(325.3756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 119, loss 325.3756103515625\n",
      "tensor(325.1982, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 120, loss 325.1982421875\n",
      "tensor(325.0208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 121, loss 325.0208435058594\n",
      "tensor(324.8437, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 122, loss 324.84368896484375\n",
      "tensor(324.6667, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 123, loss 324.66668701171875\n",
      "tensor(324.4899, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 124, loss 324.4898681640625\n",
      "tensor(324.3132, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 125, loss 324.31317138671875\n",
      "tensor(324.1366, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 126, loss 324.1366271972656\n",
      "tensor(323.9601, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 127, loss 323.96014404296875\n",
      "tensor(323.7839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 128, loss 323.78387451171875\n",
      "tensor(323.6078, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 129, loss 323.6077880859375\n",
      "tensor(323.4318, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 130, loss 323.43182373046875\n",
      "tensor(323.2559, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 131, loss 323.25592041015625\n",
      "tensor(323.0803, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 132, loss 323.080322265625\n",
      "tensor(322.9047, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 133, loss 322.90472412109375\n",
      "tensor(322.7294, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 134, loss 322.7294006347656\n",
      "tensor(322.5541, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 135, loss 322.5541076660156\n",
      "tensor(322.3790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 136, loss 322.37896728515625\n",
      "tensor(322.2040, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 137, loss 322.2040100097656\n",
      "tensor(322.0292, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 138, loss 322.02923583984375\n",
      "tensor(321.8546, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 139, loss 321.8546142578125\n",
      "tensor(321.6801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 140, loss 321.6800842285156\n",
      "tensor(321.5057, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 141, loss 321.5057067871094\n",
      "tensor(321.3315, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 142, loss 321.33148193359375\n",
      "tensor(321.1574, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 143, loss 321.15740966796875\n",
      "tensor(320.9835, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 144, loss 320.98345947265625\n",
      "tensor(320.8097, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 145, loss 320.8097229003906\n",
      "tensor(320.6360, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 146, loss 320.63604736328125\n",
      "tensor(320.4626, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 147, loss 320.46258544921875\n",
      "tensor(320.2892, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 148, loss 320.28924560546875\n",
      "tensor(320.1160, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 149, loss 320.11602783203125\n",
      "tensor(319.9429, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 150, loss 319.94293212890625\n",
      "tensor(319.7701, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 151, loss 319.7700500488281\n",
      "tensor(319.5973, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 152, loss 319.5972595214844\n",
      "tensor(319.4246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 153, loss 319.42462158203125\n",
      "tensor(319.2521, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 154, loss 319.25213623046875\n",
      "tensor(319.0798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 155, loss 319.079833984375\n",
      "tensor(318.9076, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 156, loss 318.9076232910156\n",
      "tensor(318.7356, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 157, loss 318.7355651855469\n",
      "tensor(318.5637, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 158, loss 318.56365966796875\n",
      "tensor(318.3918, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 159, loss 318.391845703125\n",
      "tensor(318.2202, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 160, loss 318.22021484375\n",
      "tensor(318.0488, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 161, loss 318.0487976074219\n",
      "tensor(317.8775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 162, loss 317.87750244140625\n",
      "tensor(317.7063, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 163, loss 317.7062683105469\n",
      "tensor(317.5352, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 164, loss 317.53521728515625\n",
      "tensor(317.3643, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 165, loss 317.3642883300781\n",
      "tensor(317.1935, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 166, loss 317.19354248046875\n",
      "tensor(317.0229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 167, loss 317.0229187011719\n",
      "tensor(316.8524, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 168, loss 316.8524475097656\n",
      "tensor(316.6821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 169, loss 316.6820983886719\n",
      "tensor(316.5119, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 170, loss 316.51190185546875\n",
      "tensor(316.3419, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 171, loss 316.34185791015625\n",
      "tensor(316.1720, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 172, loss 316.1719665527344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(316.0022, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 173, loss 316.0021667480469\n",
      "tensor(315.8326, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 174, loss 315.83258056640625\n",
      "tensor(315.6631, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 175, loss 315.6630859375\n",
      "tensor(315.4937, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 176, loss 315.4937438964844\n",
      "tensor(315.3245, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 177, loss 315.32452392578125\n",
      "tensor(315.1555, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 178, loss 315.15545654296875\n",
      "tensor(314.9865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 179, loss 314.9865417480469\n",
      "tensor(314.8177, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 180, loss 314.8177185058594\n",
      "tensor(314.6491, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 181, loss 314.64910888671875\n",
      "tensor(314.4807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 182, loss 314.48065185546875\n",
      "tensor(314.3123, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 183, loss 314.31231689453125\n",
      "tensor(314.1441, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 184, loss 314.14410400390625\n",
      "tensor(313.9760, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 185, loss 313.9760437011719\n",
      "tensor(313.8080, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 186, loss 313.80804443359375\n",
      "tensor(313.6403, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 187, loss 313.6402893066406\n",
      "tensor(313.4726, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 188, loss 313.47259521484375\n",
      "tensor(313.3051, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 189, loss 313.3050842285156\n",
      "tensor(313.1377, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 190, loss 313.1376953125\n",
      "tensor(312.9705, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 191, loss 312.9704895019531\n",
      "tensor(312.8034, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 192, loss 312.8033752441406\n",
      "tensor(312.6364, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 193, loss 312.63641357421875\n",
      "tensor(312.4696, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 194, loss 312.4696044921875\n",
      "tensor(312.3029, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 195, loss 312.3028869628906\n",
      "tensor(312.1364, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 196, loss 312.13641357421875\n",
      "tensor(311.9700, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 197, loss 311.9700012207031\n",
      "tensor(311.8037, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 198, loss 311.8037414550781\n",
      "tensor(311.6376, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch 199, loss 311.6376037597656\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Converting inputs and labels to Variable\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:19:06.905526Z",
     "start_time": "2019-10-03T11:19:06.897536Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 40.21086 ]\n",
      " [ 18.37832 ]\n",
      " [ 91.15345 ]\n",
      " [ 62.0434  ]\n",
      " [112.98599 ]\n",
      " [ 76.59843 ]\n",
      " [ 83.87594 ]\n",
      " [127.541016]\n",
      " [ 58.40464 ]\n",
      " [ 25.655834]]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    if torch.cuda.is_available():\n",
    "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
    "    else:\n",
    "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "    print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-03T11:28:40.887647Z",
     "start_time": "2019-10-03T11:28:40.705140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.title(\"Linear Regression\")\n",
    "plt.plot(x_train, y_train, 'ro', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
