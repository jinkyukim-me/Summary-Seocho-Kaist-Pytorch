{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fstyv2SWDyNG"
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBaTxvd-IcU3"
   },
   "source": [
    "## 0. SoftMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "UBc98-MkiAVS",
    "outputId": "7a397afb-8e47-47a9-98a0-da19c2551f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "\n",
    "exp_a = np.exp(a)\n",
    "\n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwpjwyzVD118"
   },
   "source": [
    "## 1. MLP VS CNN with CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGjlbeJFWOxd"
   },
   "source": [
    "### 1.1 MLP Model with CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zN4EMP9uDvPW"
   },
   "source": [
    "중요 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-SU2ruZ701H"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_w8qiHwHEFyc"
   },
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fgdhaNqlEHWw",
    "outputId": "831a92aa-ed31-4d30-ae14-734b8236e7cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "total_epoch = 50\n",
    "learning_rate = 0.01\n",
    "use_cuda = torch.cuda.is_available()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xzvgvD1ESbQ"
   },
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LQ0prMG3EQxi",
    "outputId": "5f5f0bdd-4357-464a-d31e-b75965c0a991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GJtqH-YMIiOK"
   },
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUaT2yUEIj73"
   },
   "outputs": [],
   "source": [
    "def train(model,train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        \n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        pred_label = model(image)\n",
    "        loss = criterion(pred_label, label)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJgn4fBsKXHF"
   },
   "source": [
    "Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouaNCPAUKUzF"
   },
   "outputs": [],
   "source": [
    "def eval(model, test_loader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device.index\n",
    "    \n",
    "    total_cnt = 0\n",
    "    correct_cnt = 0\n",
    "    \n",
    "    for i, (image, label) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        out = model(image)\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += image.data.size()[0]\n",
    "        correct_cnt += (pred_label == label.data).sum().item()\n",
    "        \n",
    "    return correct_cnt / total_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K9NbhDoXEkH_"
   },
   "source": [
    "CIFAR10 MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U933Akt8Ed8x"
   },
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \n",
    "        # Fully-connected layer\n",
    "        self.fc1 = nn.Linear(3*32*32, 8*28*28)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(8*28*28, 8*24*24)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(8*24*24, 16*8*8)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(16*8*8, 16*4*4)\n",
    "        self.act4 = nn.ReLU()\n",
    "\n",
    "        # Output layer\n",
    "        self.out = nn.Linear(16*4*4, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3*32*32)\n",
    "        \n",
    "        x = self.act1(self.fc1(x))\n",
    "        x = self.act2(self.fc2(x))\n",
    "        x = self.act3(self.fc3(x))\n",
    "        x = self.act4(self.fc4(x))\n",
    "        \n",
    "        out = self.out(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Xq6rmD7OG1q"
   },
   "source": [
    "Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HQKiUxZVKZY8",
    "outputId": "47629397-6fb2-4295-dbca-645acbe125cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1567\n",
      "0.2081\n",
      "0.2752\n",
      "0.308\n",
      "0.3142\n",
      "0.3395\n",
      "0.3603\n",
      "0.3466\n",
      "0.3948\n",
      "0.4015\n",
      "0.3944\n",
      "0.424\n",
      "0.4405\n",
      "0.4516\n",
      "0.4641\n",
      "0.4568\n",
      "0.4581\n",
      "0.4653\n",
      "0.4758\n",
      "0.4635\n",
      "0.4834\n",
      "0.5033\n",
      "0.5018\n",
      "0.4948\n",
      "0.4902\n",
      "0.4812\n",
      "0.5108\n",
      "0.5233\n",
      "0.4582\n",
      "0.5249\n",
      "0.5332\n",
      "0.5231\n",
      "0.4913\n",
      "0.5185\n",
      "0.5031\n",
      "0.5442\n",
      "0.496\n",
      "0.5373\n",
      "0.5375\n",
      "0.4629\n",
      "0.5337\n",
      "0.5366\n",
      "0.5282\n",
      "0.5319\n",
      "0.5477\n",
      "0.5195\n",
      "0.5525\n",
      "0.5264\n",
      "0.5632\n",
      "0.5219\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 6272]      19,273,856\n",
      "              ReLU-2                 [-1, 6272]               0\n",
      "            Linear-3                 [-1, 4608]      28,905,984\n",
      "              ReLU-4                 [-1, 4608]               0\n",
      "            Linear-5                 [-1, 1024]       4,719,616\n",
      "              ReLU-6                 [-1, 1024]               0\n",
      "            Linear-7                  [-1, 256]         262,400\n",
      "              ReLU-8                  [-1, 256]               0\n",
      "            Linear-9                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 53,164,426\n",
      "Trainable params: 53,164,426\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.19\n",
      "Params size (MB): 202.81\n",
      "Estimated Total Size (MB): 203.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mlp_model = SimpleMLP().cuda()\n",
    "train_loss_lst = []\n",
    "test_accuracy_lst = []\n",
    "for epoch in range(total_epoch):\n",
    "    train_loss = train(mlp_model, train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    test_accuracy = eval(mlp_model, test_loader)\n",
    "    test_accuracy_lst.append(test_accuracy)\n",
    "    \n",
    "    print(test_accuracy)\n",
    "\n",
    "summary(mlp_model, input_size = (3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9Y0a91SX_HZ"
   },
   "source": [
    "### 1.2 CNN Model with CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fx4EC-1vYR03"
   },
   "source": [
    "중요 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A0D93zO-NW98"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8i7SC2p1YUjJ"
   },
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "g5iG75TMYZKf",
    "outputId": "0a6166eb-87a6-42de-b6bb-e27a3d5474b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "total_epoch = 50\n",
    "learning_rate = 0.001\n",
    "use_cuda = torch.cuda.is_available()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkXJo4AfYZ7l"
   },
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mHaKdbG6YcbV",
    "outputId": "05eb31f8-cac2-4e49-c43d-ad3b43196a4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKPHAJKEYhWd"
   },
   "source": [
    "CIFAR10 CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4RZONSjJm1O"
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolution layer\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully-Connected layer\n",
    "        self.fc1 = nn.Linear(256 * 2* 2, 1000)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.output = nn.Linear(1000, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.act1(self.conv1(x)))\n",
    "        x = self.pool2(self.act2(self.conv2(x)))\n",
    "        x = self.act3(self.conv3(x))\n",
    "        x = self.act4(self.conv4(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        \n",
    "        x = self.act5(self.fc1(x))\n",
    "        out = self.output(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BscJ3eLRQB6j"
   },
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqEP2Xk4OSAt"
   },
   "outputs": [],
   "source": [
    "def train(model,train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        \n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        pred_label = model(image)\n",
    "        loss = criterion(pred_label, label)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqg3JnTRQEIs"
   },
   "source": [
    "Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdbhRae8OUAV"
   },
   "outputs": [],
   "source": [
    "def eval(model, test_loader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device.index\n",
    "    \n",
    "    total_cnt = 0\n",
    "    correct_cnt = 0\n",
    "    \n",
    "    for i, (image, label) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        out = model(image)\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += image.data.size()[0]\n",
    "        correct_cnt += (pred_label == label.data).sum().item()\n",
    "        \n",
    "    return correct_cnt / total_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7n0U0gZQGyH"
   },
   "source": [
    "Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eciwGiTHNJoM",
    "outputId": "2b34a1db-0278-4c53-f05b-abcebf1fd8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1007\n",
      "0.1143\n",
      "0.1852\n",
      "0.2514\n",
      "0.2611\n",
      "0.2856\n",
      "0.2866\n",
      "0.3274\n",
      "0.3762\n",
      "0.3845\n",
      "0.4125\n",
      "0.4276\n",
      "0.4374\n",
      "0.4615\n",
      "0.473\n",
      "0.4891\n",
      "0.4941\n",
      "0.4858\n",
      "0.5053\n",
      "0.5111\n",
      "0.4971\n",
      "0.5579\n",
      "0.5513\n",
      "0.5728\n",
      "0.5844\n",
      "0.5792\n",
      "0.5828\n",
      "0.601\n",
      "0.6087\n",
      "0.6155\n",
      "0.6067\n",
      "0.6223\n",
      "0.6386\n",
      "0.6408\n",
      "0.6396\n",
      "0.651\n",
      "0.6619\n",
      "0.664\n",
      "0.6717\n",
      "0.6721\n",
      "0.6723\n",
      "0.6663\n",
      "0.6341\n",
      "0.675\n",
      "0.6851\n",
      "0.6996\n",
      "0.698\n",
      "0.6956\n",
      "0.69\n",
      "0.6909\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           1,792\n",
      "              ReLU-2           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-3             [-1, 64, 8, 8]               0\n",
      "            Conv2d-4            [-1, 192, 8, 8]         110,784\n",
      "              ReLU-5            [-1, 192, 8, 8]               0\n",
      "         MaxPool2d-6            [-1, 192, 4, 4]               0\n",
      "            Conv2d-7            [-1, 384, 4, 4]         663,936\n",
      "              ReLU-8            [-1, 384, 4, 4]               0\n",
      "            Conv2d-9            [-1, 256, 4, 4]         884,992\n",
      "             ReLU-10            [-1, 256, 4, 4]               0\n",
      "        MaxPool2d-11            [-1, 256, 2, 2]               0\n",
      "           Linear-12                 [-1, 1000]       1,025,000\n",
      "             ReLU-13                 [-1, 1000]               0\n",
      "           Linear-14                   [-1, 10]          10,010\n",
      "================================================================\n",
      "Total params: 2,696,514\n",
      "Trainable params: 2,696,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.67\n",
      "Params size (MB): 10.29\n",
      "Estimated Total Size (MB): 10.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cnn_model = SimpleCNN().cuda()\n",
    "train_loss_lst = []\n",
    "test_accuracy_lst = []\n",
    "for epoch in range(total_epoch):\n",
    "    train_loss = train(cnn_model, train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    test_accuracy = eval(cnn_model, test_loader)\n",
    "    test_accuracy_lst.append(test_accuracy)\n",
    "    \n",
    "    print(test_accuracy)\n",
    "\n",
    "summary(cnn_model, input_size = (3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhXAk5P_QgHJ"
   },
   "source": [
    "## 2. VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "zXdpPZHoAdU7",
    "outputId": "4a039bbf-1c60-43f6-e951-ce00c10f1e5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 170467328/170498071 [05:01<00:00, 404156.12it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "total_epoch = 50\n",
    "learning_rate = 0.01\n",
    "use_cuda = torch.cuda.is_available()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(use_cuda)\n",
    "\n",
    "train_dataset = dsets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = dsets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def train(model,train_loader):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    losses = []\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        \n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        pred_label = model(image)\n",
    "        loss = criterion(pred_label, label)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def eval(model, test_loader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device.index\n",
    "    \n",
    "    total_cnt = 0\n",
    "    correct_cnt = 0\n",
    "    \n",
    "    for i, (image, label) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            image = image.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        out = model(image)\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += image.data.size()[0]\n",
    "        correct_cnt += (pred_label == label.data).sum().item()\n",
    "        \n",
    "    return correct_cnt / total_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KbC0bf8RQhYa"
   },
   "outputs": [],
   "source": [
    "class SimpleVGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleVGG, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act3_1 = nn.ReLU()\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act3_2 = nn.ReLU()\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act3_3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act4_1 = nn.ReLU()\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act4_2 = nn.ReLU()\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act4_3 = nn.ReLU()\n",
    "        self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc1 = nn.Linear(512 * 2 * 2, 512)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.out = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = x\n",
    "        x2 = self.act1(self.conv1(x1))\n",
    "        x3 = self.pool1(x2)\n",
    "        \n",
    "        x4 = self.act2(self.conv2(x3))\n",
    "        x5 = self.pool2(x4)\n",
    "        \n",
    "        x6 = self.act3_1(self.conv3_1(x5))\n",
    "        x7 = self.act3_2(self.conv3_2(x6))\n",
    "        x8 = self.act3_3(self.conv3_2(x7))\n",
    "        x9 = self.pool3(x8)\n",
    "        \n",
    "        x10 = self.act4_1(self.conv4_1(x9))\n",
    "        x11 = self.act4_2(self.conv4_2(x10))\n",
    "        x12 = self.act4_3(self.conv4_2(x11))\n",
    "        x13 = self.pool4(x12)\n",
    "        \n",
    "        x14 = x13.view(-1, 512 * 2 * 2)\n",
    "        \n",
    "        x15 = self.act5(self.fc1(x14))\n",
    "        \n",
    "        out = self.out(x15)        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "lcxQ5h2eQyG_",
    "outputId": "30c80c09-ba0a-48ff-dd9c-950cca514ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-02d4c74f56b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_accuracy_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loss_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-352000185b79>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;31m# print(encoder, mode, args + extra)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder %s not available\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vgg_model = SimpleVGG().cuda()\n",
    "train_loss_lst = []\n",
    "test_accuracy_lst = []\n",
    "for epoch in range(total_epoch):\n",
    "    train_loss = train(vgg_model, train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    test_accuracy = eval(vgg_model, test_loader)\n",
    "    test_accuracy_lst.append(test_accuracy)\n",
    "    \n",
    "    print(test_accuracy)\n",
    "\n",
    "summary(vgg_model, input_size = (3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAHIX381dTCg"
   },
   "source": [
    "## 3. ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hCVBYF7eDy_z"
   },
   "outputs": [],
   "source": [
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act3_1 = nn.ReLU()\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act3_2 = nn.ReLU()\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act3_3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act4_1 = nn.ReLU()\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act4_2 = nn.ReLU()\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=(3,3), padding=(1,1))\n",
    "        self.act4_3 = nn.ReLU()\n",
    "        self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc1 = nn.Linear(512 * 2 * 2, 512)\n",
    "        self.act5 = nn.ReLU()\n",
    "        self.out = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = x\n",
    "        x2 = self.act1(self.conv1(x1))\n",
    "        x3 = self.pool1(x2)\n",
    "        \n",
    "        x4 = self.act2(self.conv2(x3))\n",
    "        x5 = self.pool2(x4)\n",
    "        \n",
    "        x6 = self.act3_1(self.conv3_1(x5))\n",
    "        x7 = self.act3_2(self.conv3_2(x6))\n",
    "        x8 = self.act3_3(self.conv3_2(x7) + x6)\n",
    "        x9 = self.pool3(x8)\n",
    "        \n",
    "        x10 = self.act4_1(self.conv4_1(x9))\n",
    "        x11 = self.act4_2(self.conv4_2(x10))\n",
    "        x12 = self.act4_3(self.conv4_2(x11) + x10)\n",
    "        x13 = self.pool4(x12)\n",
    "        \n",
    "        x14 = x13.view(-1, 512 * 2 * 2)\n",
    "        \n",
    "        x15 = self.act5(self.fc1(x14))\n",
    "        \n",
    "        out = self.out(x15)        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "rfAjbei8dUq-",
    "outputId": "ab5b410b-62f9-43da-8702-684bd68252ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1446\n",
      "0.1608\n",
      "0.1415\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-193af24a18dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_accuracy_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loss_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-352000185b79>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resnet_model = SimpleResNet().cuda()\n",
    "train_loss_lst = []\n",
    "test_accuracy_lst = []\n",
    "for epoch in range(total_epoch):\n",
    "    train_loss = train(resnet_model, train_loader)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    test_accuracy = eval(resnet_model, test_loader)\n",
    "    test_accuracy_lst.append(test_accuracy)\n",
    "    \n",
    "    print(test_accuracy)\n",
    "\n",
    "summary(resnet_model, input_size = (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "colab_type": "code",
    "id": "VOZu47kQSP1E",
    "outputId": "db607cd4-d9b5-419a-af48-d8bfd045bce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 64, 16, 16]               0\n",
      "            Conv2d-4          [-1, 128, 16, 16]          73,856\n",
      "              ReLU-5          [-1, 128, 16, 16]               0\n",
      "         MaxPool2d-6            [-1, 128, 8, 8]               0\n",
      "            Conv2d-7            [-1, 256, 8, 8]         295,168\n",
      "              ReLU-8            [-1, 256, 8, 8]               0\n",
      "            Conv2d-9            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-10            [-1, 256, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-12            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-13            [-1, 256, 4, 4]               0\n",
      "           Conv2d-14            [-1, 512, 4, 4]       1,180,160\n",
      "             ReLU-15            [-1, 512, 4, 4]               0\n",
      "           Conv2d-16            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-17            [-1, 512, 4, 4]               0\n",
      "           Conv2d-18            [-1, 512, 4, 4]       2,359,808\n",
      "             ReLU-19            [-1, 512, 4, 4]               0\n",
      "        AvgPool2d-20            [-1, 512, 2, 2]               0\n",
      "           Linear-21                  [-1, 512]       1,049,088\n",
      "             ReLU-22                  [-1, 512]               0\n",
      "           Linear-23                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 8,504,970\n",
      "Trainable params: 8,504,970\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 2.87\n",
      "Params size (MB): 32.44\n",
      "Estimated Total Size (MB): 35.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet_model, input_size = (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIRHxAXdQ9RZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3.CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
