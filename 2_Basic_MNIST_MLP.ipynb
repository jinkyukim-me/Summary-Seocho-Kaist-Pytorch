{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYnWE9diaVBn"
   },
   "source": [
    "## 중요 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4G2YZLDZ_xg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmo2MZUOaeNA"
   },
   "source": [
    "## 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDxplYYeahnL"
   },
   "outputs": [],
   "source": [
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lp1oov3Fatkw"
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
    "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhsW6kddc2_P"
   },
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIUka0ricnld"
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "batch_size = 100\n",
    "total_epoch = 10\n",
    "learning_rate = 0.01\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XuE7fKPjc8_3"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1881,
     "status": "ok",
     "timestamp": 1570121649083,
     "user": {
      "displayName": "Jinkyu Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI3V4v2jgGjDWZ9LguiZGukfMnweTODPPC0mGktMA=s64",
      "userId": "17799218152297571837"
     },
     "user_tz": -540
    },
    "id": "3NDBfZEKc0PL",
    "outputId": "9b2e0fe4-dcad-4dbf-feb3-725f31680179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> total trainning batch number: 600\n",
      "==>> total testing batch number: 600\n"
     ]
    }
   ],
   "source": [
    "# Data Loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
    "print('==>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "print('==>> total testing batch number: {}'.format(len(train_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Kji_bGNdISE"
   },
   "source": [
    "## MNIST MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01sIPAuRc_fa"
   },
   "outputs": [],
   "source": [
    "# MNIST MLP Model\n",
    "\n",
    "class MLPNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"MLP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTyE1uUEdWN-"
   },
   "outputs": [],
   "source": [
    "model = MLPNet()\n",
    "if use_cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MOeHT7KRhlMR"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss() # 이미지 분류 모델은 일반적으로 CrossEntropy Loss Function을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-V6stbBh2Bn"
   },
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 125964,
     "status": "ok",
     "timestamp": 1570121773227,
     "user": {
      "displayName": "Jinkyu Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI3V4v2jgGjDWZ9LguiZGukfMnweTODPPC0mGktMA=s64",
      "userId": "17799218152297571837"
     },
     "user_tz": -540
    },
    "id": "f5j0WT7hh6r8",
    "outputId": "ef2c1dec-5c3e-407a-e0a8-58e9225dea93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> epoch : 0, batch index : 100, train loss : 2.276442\n",
      "==>>> epoch : 0, batch index : 200, train loss : 2.238402\n",
      "==>>> epoch : 0, batch index : 300, train loss : 2.182269\n",
      "==>>> epoch : 0, batch index : 400, train loss : 2.097447\n",
      "==>>> epoch : 0, batch index : 500, train loss : 1.981809\n",
      "==>>> epoch : 0, batch index : 600, train loss : 1.850448\n",
      "==>>> epoch : 0, batch index : 100, train loss : 1.046063, acc: 0.767\n",
      "==>>> epoch : 1, batch index : 100, train loss : 0.955229\n",
      "==>>> epoch : 1, batch index : 200, train loss : 0.883414\n",
      "==>>> epoch : 1, batch index : 300, train loss : 0.823376\n",
      "==>>> epoch : 1, batch index : 400, train loss : 0.777982\n",
      "==>>> epoch : 1, batch index : 500, train loss : 0.739135\n",
      "==>>> epoch : 1, batch index : 600, train loss : 0.707983\n",
      "==>>> epoch : 1, batch index : 100, train loss : 0.507554, acc: 0.860\n",
      "==>>> epoch : 2, batch index : 100, train loss : 0.506529\n",
      "==>>> epoch : 2, batch index : 200, train loss : 0.494346\n",
      "==>>> epoch : 2, batch index : 300, train loss : 0.486796\n",
      "==>>> epoch : 2, batch index : 400, train loss : 0.478729\n",
      "==>>> epoch : 2, batch index : 500, train loss : 0.470871\n",
      "==>>> epoch : 2, batch index : 600, train loss : 0.462284\n",
      "==>>> epoch : 2, batch index : 100, train loss : 0.399046, acc: 0.886\n",
      "==>>> epoch : 3, batch index : 100, train loss : 0.412127\n",
      "==>>> epoch : 3, batch index : 200, train loss : 0.410677\n",
      "==>>> epoch : 3, batch index : 300, train loss : 0.402235\n",
      "==>>> epoch : 3, batch index : 400, train loss : 0.397881\n",
      "==>>> epoch : 3, batch index : 500, train loss : 0.394928\n",
      "==>>> epoch : 3, batch index : 600, train loss : 0.392204\n",
      "==>>> epoch : 3, batch index : 100, train loss : 0.356805, acc: 0.896\n",
      "==>>> epoch : 4, batch index : 100, train loss : 0.371510\n",
      "==>>> epoch : 4, batch index : 200, train loss : 0.365462\n",
      "==>>> epoch : 4, batch index : 300, train loss : 0.360886\n",
      "==>>> epoch : 4, batch index : 400, train loss : 0.360300\n",
      "==>>> epoch : 4, batch index : 500, train loss : 0.361047\n",
      "==>>> epoch : 4, batch index : 600, train loss : 0.357705\n",
      "==>>> epoch : 4, batch index : 100, train loss : 0.331976, acc: 0.902\n",
      "==>>> epoch : 5, batch index : 100, train loss : 0.334884\n",
      "==>>> epoch : 5, batch index : 200, train loss : 0.336726\n",
      "==>>> epoch : 5, batch index : 300, train loss : 0.336370\n",
      "==>>> epoch : 5, batch index : 400, train loss : 0.334144\n",
      "==>>> epoch : 5, batch index : 500, train loss : 0.334236\n",
      "==>>> epoch : 5, batch index : 600, train loss : 0.335373\n",
      "==>>> epoch : 5, batch index : 100, train loss : 0.312849, acc: 0.909\n",
      "==>>> epoch : 6, batch index : 100, train loss : 0.326592\n",
      "==>>> epoch : 6, batch index : 200, train loss : 0.331945\n",
      "==>>> epoch : 6, batch index : 300, train loss : 0.323848\n",
      "==>>> epoch : 6, batch index : 400, train loss : 0.321583\n",
      "==>>> epoch : 6, batch index : 500, train loss : 0.320116\n",
      "==>>> epoch : 6, batch index : 600, train loss : 0.318306\n",
      "==>>> epoch : 6, batch index : 100, train loss : 0.300343, acc: 0.912\n",
      "==>>> epoch : 7, batch index : 100, train loss : 0.320958\n",
      "==>>> epoch : 7, batch index : 200, train loss : 0.309452\n",
      "==>>> epoch : 7, batch index : 300, train loss : 0.306626\n",
      "==>>> epoch : 7, batch index : 400, train loss : 0.305374\n",
      "==>>> epoch : 7, batch index : 500, train loss : 0.304654\n",
      "==>>> epoch : 7, batch index : 600, train loss : 0.304119\n",
      "==>>> epoch : 7, batch index : 100, train loss : 0.290068, acc: 0.917\n",
      "==>>> epoch : 8, batch index : 100, train loss : 0.293727\n",
      "==>>> epoch : 8, batch index : 200, train loss : 0.292308\n",
      "==>>> epoch : 8, batch index : 300, train loss : 0.288393\n",
      "==>>> epoch : 8, batch index : 400, train loss : 0.290866\n",
      "==>>> epoch : 8, batch index : 500, train loss : 0.290765\n",
      "==>>> epoch : 8, batch index : 600, train loss : 0.292063\n",
      "==>>> epoch : 8, batch index : 100, train loss : 0.278373, acc: 0.920\n",
      "==>>> epoch : 9, batch index : 100, train loss : 0.274014\n",
      "==>>> epoch : 9, batch index : 200, train loss : 0.286701\n",
      "==>>> epoch : 9, batch index : 300, train loss : 0.281974\n",
      "==>>> epoch : 9, batch index : 400, train loss : 0.283680\n",
      "==>>> epoch : 9, batch index : 500, train loss : 0.281923\n",
      "==>>> epoch : 9, batch index : 600, train loss : 0.281072\n",
      "==>>> epoch : 9, batch index : 100, train loss : 0.268686, acc: 0.924\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    # trainning\n",
    "    total_loss = 0\n",
    "    total_batch = 0\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        total_loss += loss.item()\n",
    "        total_batch += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            print('==>>> epoch : {}, batch index : {}, train loss : {:.6f}'\n",
    "                  .format(epoch, batch_idx+1, total_loss/total_batch))\n",
    "    # testing\n",
    "    total_loss = 0\n",
    "    total_batch = 0\n",
    "    correct_cnt = 0\n",
    "    total_cnt = 0\n",
    "    for batch_idx, (x, target) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, target)\n",
    "        _, pred_label = torch.max(out.data, 1)\n",
    "        total_cnt += x.data.size()[0]\n",
    "        correct_cnt += (pred_label == target.data).sum().item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_batch += 1\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(test_loader):\n",
    "            print('==>>> epoch : {}, batch index : {}, train loss : {:.6f}, acc: {:.3f}'\n",
    "                  .format(epoch, batch_idx + 1, total_loss / total_batch, correct_cnt * 1.0 / total_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFQx5yN5icCt"
   },
   "source": [
    "<p><img src=\"https://github.com/jinkyukim-me/Summary-Seocho-Pytorch/blob/master/img/basic_MNIST_MLP.JPG\" width=\"100%\"></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "2_Basic_MNIST_MLP.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
