{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2_Basic_MNIST_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinkyukim-me/Summary-Seocho-Pytorch/blob/master/2_Basic_MNIST_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jYnWE9diaVBn"
      },
      "source": [
        "## 중요 모듈 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s4G2YZLDZ_xg",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wmo2MZUOaeNA"
      },
      "source": [
        "## 데이터 셋"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LDxplYYeahnL",
        "colab": {}
      },
      "source": [
        "root = './data'\n",
        "if not os.path.exists(root):\n",
        "    os.mkdir(root)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lp1oov3Fatkw",
        "colab": {}
      },
      "source": [
        "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "train_set = dset.MNIST(root=root, train=True, transform=trans, download=True)\n",
        "test_set = dset.MNIST(root=root, train=False, transform=trans, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AhsW6kddc2_P"
      },
      "source": [
        "## Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oIUka0ricnld",
        "colab": {}
      },
      "source": [
        "# Hyper Parameters\n",
        "batch_size = 100\n",
        "total_epoch = 10\n",
        "learning_rate = 0.01\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XuE7fKPjc8_3"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3NDBfZEKc0PL",
        "outputId": "bcc39e6b-54b5-44b2-d71e-0561887142b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Data Loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
        "print('==>> total trainning batch number: {}'.format(len(train_loader)))\n",
        "print('==>> total testing batch number: {}'.format(len(train_loader)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==>> total trainning batch number: 600\n",
            "==>> total testing batch number: 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Kji_bGNdISE"
      },
      "source": [
        "## MNIST MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "01sIPAuRc_fa",
        "colab": {}
      },
      "source": [
        "# MNIST MLP Model\n",
        "\n",
        "class MLPNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 500)\n",
        "        self.fc2 = nn.Linear(500, 256)\n",
        "        self.fc3 = nn.Linear(256, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "    def name(self):\n",
        "        return \"MLP\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTyE1uUEdWN-",
        "colab": {}
      },
      "source": [
        "model = MLPNet()\n",
        "if use_cuda:\n",
        "    model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MOeHT7KRhlMR",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss() # 이미지 분류 모델은 일반적으로 CrossEntropy Loss Function을 사용"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B-V6stbBh2Bn"
      },
      "source": [
        "## 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f5j0WT7hh6r8",
        "outputId": "60296a1c-855f-4c00-ed55-e052d26b6c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(total_epoch):\n",
        "    # trainning\n",
        "    total_loss = 0\n",
        "    total_batch = 0\n",
        "    loss_lst=[]\n",
        "    for batch_idx, (x, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        if use_cuda:\n",
        "            x, target = x.cuda(), target.cuda()\n",
        "\n",
        "        out = model(x)\n",
        "        loss = criterion(out, target)      \n",
        "        total_loss += loss.item()\n",
        "        total_batch += 1\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(train_loader):\n",
        "            print('==>>> epoch : {}, batch index : {}, train loss : {:.6f}'\n",
        "                  .format(epoch, batch_idx+1, total_loss/total_batch))   \n",
        "\n",
        "    # testing\n",
        "    total_loss = 0\n",
        "    total_batch = 0\n",
        "    correct_cnt = 0\n",
        "    total_cnt = 0\n",
        "    acc_lst =[]\n",
        "    for batch_idx, (x, target) in enumerate(test_loader):\n",
        "        if use_cuda:\n",
        "            x, target = x.cuda(), target.cuda()\n",
        "\n",
        "        out = model(x)\n",
        "        loss = criterion(out, target)\n",
        "        _, pred_label = torch.max(out.data, 1)\n",
        "        total_cnt += x.data.size()[0]\n",
        "        correct_cnt += (pred_label == target.data).sum().item()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        total_batch += 1\n",
        "        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(test_loader):\n",
        "            print('==>>> epoch : {}, batch index : {}, train loss : {:.6f}, acc: {:.3f}'\n",
        "                  .format(epoch, batch_idx + 1, total_loss / total_batch, correct_cnt * 1.0 / total_cnt))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==>>> epoch : 0, batch index : 100, train loss : 2.271389\n",
            "==>>> epoch : 0, batch index : 200, train loss : 2.230830\n",
            "==>>> epoch : 0, batch index : 300, train loss : 2.172551\n",
            "==>>> epoch : 0, batch index : 400, train loss : 2.087003\n",
            "==>>> epoch : 0, batch index : 500, train loss : 1.972406\n",
            "==>>> epoch : 0, batch index : 600, train loss : 1.845510\n",
            "==>>> epoch : 0, batch index : 100, train loss : 1.062150, acc: 0.763\n",
            "==>>> epoch : 1, batch index : 100, train loss : 0.975043\n",
            "==>>> epoch : 1, batch index : 200, train loss : 0.899841\n",
            "==>>> epoch : 1, batch index : 300, train loss : 0.839800\n",
            "==>>> epoch : 1, batch index : 400, train loss : 0.793164\n",
            "==>>> epoch : 1, batch index : 500, train loss : 0.752271\n",
            "==>>> epoch : 1, batch index : 600, train loss : 0.717686\n",
            "==>>> epoch : 1, batch index : 100, train loss : 0.516536, acc: 0.864\n",
            "==>>> epoch : 2, batch index : 100, train loss : 0.511792\n",
            "==>>> epoch : 2, batch index : 200, train loss : 0.500431\n",
            "==>>> epoch : 2, batch index : 300, train loss : 0.487044\n",
            "==>>> epoch : 2, batch index : 400, train loss : 0.475292\n",
            "==>>> epoch : 2, batch index : 500, train loss : 0.469421\n",
            "==>>> epoch : 2, batch index : 600, train loss : 0.462031\n",
            "==>>> epoch : 2, batch index : 100, train loss : 0.400385, acc: 0.888\n",
            "==>>> epoch : 3, batch index : 100, train loss : 0.416942\n",
            "==>>> epoch : 3, batch index : 200, train loss : 0.405843\n",
            "==>>> epoch : 3, batch index : 300, train loss : 0.403242\n",
            "==>>> epoch : 3, batch index : 400, train loss : 0.399376\n",
            "==>>> epoch : 3, batch index : 500, train loss : 0.393872\n",
            "==>>> epoch : 3, batch index : 600, train loss : 0.389975\n",
            "==>>> epoch : 3, batch index : 100, train loss : 0.355569, acc: 0.899\n",
            "==>>> epoch : 4, batch index : 100, train loss : 0.367710\n",
            "==>>> epoch : 4, batch index : 200, train loss : 0.363603\n",
            "==>>> epoch : 4, batch index : 300, train loss : 0.363593\n",
            "==>>> epoch : 4, batch index : 400, train loss : 0.359411\n",
            "==>>> epoch : 4, batch index : 500, train loss : 0.357375\n",
            "==>>> epoch : 4, batch index : 600, train loss : 0.354785\n",
            "==>>> epoch : 4, batch index : 100, train loss : 0.327231, acc: 0.906\n",
            "==>>> epoch : 5, batch index : 100, train loss : 0.337470\n",
            "==>>> epoch : 5, batch index : 200, train loss : 0.335810\n",
            "==>>> epoch : 5, batch index : 300, train loss : 0.334201\n",
            "==>>> epoch : 5, batch index : 400, train loss : 0.334144\n",
            "==>>> epoch : 5, batch index : 500, train loss : 0.332154\n",
            "==>>> epoch : 5, batch index : 600, train loss : 0.332418\n",
            "==>>> epoch : 5, batch index : 100, train loss : 0.310148, acc: 0.911\n",
            "==>>> epoch : 6, batch index : 100, train loss : 0.324317\n",
            "==>>> epoch : 6, batch index : 200, train loss : 0.323729\n",
            "==>>> epoch : 6, batch index : 300, train loss : 0.318629\n",
            "==>>> epoch : 6, batch index : 400, train loss : 0.318952\n",
            "==>>> epoch : 6, batch index : 500, train loss : 0.317593\n",
            "==>>> epoch : 6, batch index : 600, train loss : 0.316267\n",
            "==>>> epoch : 6, batch index : 100, train loss : 0.296216, acc: 0.914\n",
            "==>>> epoch : 7, batch index : 100, train loss : 0.292142\n",
            "==>>> epoch : 7, batch index : 200, train loss : 0.298923\n",
            "==>>> epoch : 7, batch index : 300, train loss : 0.304820\n",
            "==>>> epoch : 7, batch index : 400, train loss : 0.304406\n",
            "==>>> epoch : 7, batch index : 500, train loss : 0.305394\n",
            "==>>> epoch : 7, batch index : 600, train loss : 0.302349\n",
            "==>>> epoch : 7, batch index : 100, train loss : 0.288342, acc: 0.915\n",
            "==>>> epoch : 8, batch index : 100, train loss : 0.289836\n",
            "==>>> epoch : 8, batch index : 200, train loss : 0.294137\n",
            "==>>> epoch : 8, batch index : 300, train loss : 0.292921\n",
            "==>>> epoch : 8, batch index : 400, train loss : 0.291094\n",
            "==>>> epoch : 8, batch index : 500, train loss : 0.291054\n",
            "==>>> epoch : 8, batch index : 600, train loss : 0.291177\n",
            "==>>> epoch : 8, batch index : 100, train loss : 0.277873, acc: 0.920\n",
            "==>>> epoch : 9, batch index : 100, train loss : 0.292063\n",
            "==>>> epoch : 9, batch index : 200, train loss : 0.287491\n",
            "==>>> epoch : 9, batch index : 300, train loss : 0.281661\n",
            "==>>> epoch : 9, batch index : 400, train loss : 0.284637\n",
            "==>>> epoch : 9, batch index : 500, train loss : 0.283416\n",
            "==>>> epoch : 9, batch index : 600, train loss : 0.280751\n",
            "==>>> epoch : 9, batch index : 100, train loss : 0.267832, acc: 0.923\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}